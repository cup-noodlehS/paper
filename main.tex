\documentclass[12pt]{report}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[style=apa,backend=biber]{biblatex}

\addbibresource{refs.bib}

\setstretch{2}

\begin{document}

% Title page
\begin{titlepage}
  \centering
  \includegraphics[height=100pt]{images/up_logo.png}\par
  \vspace{1.5em}
  \textbf{AI-Driven Traffic Violation Detection Using Multi-Object Tracking and Geometric Rules in Philippine Road Environments}\par
  \vspace{1.5em}
  \textbf{A Special Project Proposal Presented to the}\par
  \textbf{Faculty of the Department of Computer Science,}\par
  \textbf{University of the Philippines Cebu}\par
  \vspace{1.5em}
  \textbf{In Partial Fulfillment}\par
  \textbf{Of the Requirements for the Degree}\par
  \textbf{Bachelor of Science in Computer Science}\par
  \vspace{1.5em}
  \textbf{SHELDON ARTHUR M. SAGRADO}\par
  BS Computer Science\par
  \vspace{1.5em}
  \textbf{DHARRYL PRINCE ABELLANA}\par
  Special Problem Adviser\par
  \vspace{1.5em}
  \textbf{December 2025}\par
\end{titlepage}

% Approval/availability page
\begin{titlepage}
  \centering
  \includegraphics[height=100pt]{images/up_logo.png}\par
  \vspace{1.5em}
  \textbf{UNIVERSITY OF THE PHILIPPINES CEBU}\par
  \textbf{College of Science}\par
  \textbf{Department of Computer Science}\par
  \vspace{1.5em}
  \textbf{AI-Driven Traffic Violation Detection Using Multi-Object Tracking and Geometric Rules in Philippine Road Environments}\par
  \vspace{1.5em}
  \textbf{Permission is given for the following people to have access to this thesis:}\par
  \vspace{1em}
  \begin{center}
    \begin{tabular}{cc}
      Available to the general public & Yes \\
      \textbf{Available only after consultation with the author or thesis adviser} & \textbf{Yes} \\
      \textbf{Available to those bound by a confidentiality agreement} & \textbf{Yes} \\
    \end{tabular}
  \end{center}
  \vspace{1.5em}
  \textbf{SHELDON ARTHUR M. SAGRADO}\par
  Student\par
  \vspace{1.5em}
  \textbf{DHARRYL PRINCE ABELLANA}\par
  Special Problem Adviser\par
\end{titlepage}

\tableofcontents
\newpage

\chapter{THE PROBLEM AND ITS SCOPE}
\section{Rationale}
Road traffic injuries remain a major public-safety concern, causing about 1.19 million deaths globally each year, with the burden falling disproportionately on low- and middle-income countries where most road fatalities occur \parencite{WHO2023Road}. In the Philippines, road crashes continue to impose substantial losses, with the WHO estimating 11,062 road traffic fatalities in 2021 \parencite{WHO2023PH}. Strengthening compliance with traffic laws is therefore a practical lever for improving road safety, but conventional, fully manual enforcement is difficult to scale consistently across dense urban road networks \parencite{Olugbade2022}. As a response, jurisdictions increasingly use camera-based enforcement and video analytics, as reflected locally by the No-Contact Apprehension Policy (NCAP) that relies on recorded visual evidence for apprehension and adjudication \parencite{MMDA2022}. However, real-world deployments face persistent technical issues---such as congestion, occlusion, viewpoint changes, and illumination variability---that directly affect the reliability of detection and tracking in traffic scenes \parencite{Wen2020}. In addition, computer vision models trained on popular datasets can exhibit dataset bias and degraded performance under distribution shift, which can manifest as inconsistent detections across vehicle types and appearances that differ from the original training domain, and such inconsistencies can propagate to unstable identities in Multi-Object Tracking (MOT) and undermine trajectory-based violation reasoning \parencite{Koh2021,TorralbaEfros2011,Wen2020}. Prior work shows that automated traffic-violation detection commonly uses a pipeline of object detection (e.g., You Only Look Once [YOLO]) plus MOT plus rule/behavior analysis, enabling offense inference from trajectories rather than single-frame cues \parencite{Olugbade2022,RedmonFarhadi2018,Zhang2022}. Because enforcement systems also benefit from transparent and auditable decision logic, coupling learned perception (detections and tracks) with geometric and lane-based rules provides a more interpretable basis for violation reasoning than purely end-to-end black-box offense classification \parencite{Olugbade2022,Rathore2021}. Motivated by these constraints, the study further incorporates fuzzy logic as a mechanism for representing and managing uncertainty in tracking decisions, consistent with the fuzzy set approach to reasoning under imprecision \parencite{Zadeh1965} and with prior research applying fuzzy decision mechanisms in video tracking contexts \parencite{Fakhri2023}.
\section{Statement of the Problem}
Artificial intelligence (AI)-based automated traffic-violation detection can help scale monitoring and evidence capture, but practical deployment depends on building a vision pipeline that remains reliable under real traffic conditions, where congestion and occlusions are frequent and where detection confidence can fluctuate across frames \parencite{Olugbade2022,Wen2020}. Performance can further degrade under adverse weather and challenging lighting (e.g., rain and glare), increasing the risk of missed detections and unstable tracks that weaken trajectory-based inference \parencite{Brophy2023,Wen2020}. Moreover, because popular pre-trained object detectors may not generalize consistently under distribution shift, inconsistencies in detections and class outputs can occur in deployment environments that differ from training datasets, which can destabilize MOT associations and reduce the reliability of geometric rule-based violation detection \parencite{Koh2021,TorralbaEfros2011,Zhang2022}. Guided by these realities and by the operational direction of camera-based enforcement that relies on recorded video evidence \parencite{MMDA2022}, this study addresses the following problems:

\begin{enumerate}
  \item \textbf{Detection Consistency for Tracking:} How can a YOLO-based detector be configured and evaluated so that its outputs remain sufficiently consistent across frames and traffic conditions to support downstream MOT and geometric violation inference? \parencite{RedmonFarhadi2018,Wen2020}
  \item \textbf{Uncertainty-Handling in MOT via Fuzzy Logic:} How can fuzzy logic be integrated into MOT decision-making (e.g., association or class-consistency handling) to manage uncertainty arising from detector-score fluctuations and out-of-distribution conditions, thereby improving track stability for enforcement-grade trajectory analysis? \parencite{Fakhri2023,Zadeh1965,Zhang2022}
  \item \textbf{Geometric Rule-Based Violation Inference:} How can deterministic geometric rules (e.g., lane/region constraints and boundary-crossing logic) be formulated and validated so that violations inferred from tracks are consistent, explainable, and scenario-appropriate? \parencite{Rathore2021,Olugbade2022}
  \item \textbf{Speed Estimation From Trajectories:} How can camera-based speed estimation (when needed for enforcement logic) be implemented in a measurable and repeatable way so that error propagation into speed-related decisions is minimized? \parencite{Olugbade2022,Shubho2021}
  \item \textbf{Weather and Lighting Resilience:} How can the pipeline mitigate performance degradation caused by rain, glare, and low-light conditions common in outdoor surveillance so that detection and tracking remain usable for evidence generation? \parencite{Brophy2023,Wen2020}
  \item \textbf{Evidence Packaging for Review:} How can the system generate a clear evidence bundle (e.g., annotated frames, timestamps, track identifiers, and rule-trigger traces) aligned with no-contact apprehension workflows that rely on video evidence? \parencite{MMDA2022,Olugbade2022}
\end{enumerate}
\section{Research Objectives}
This study aims to develop and evaluate an artificial intelligence (AI)-driven traffic violation detection pipeline that combines YOLO-based vehicle detection with multi-object tracking (MOT) and deterministic geometric rules, so that violations can be inferred from trajectory behavior over time rather than relying only on single-frame cues \parencite{RedmonFarhadi2018,Zhang2022}. The study is designed around the practical observation that deploying popular pre-trained detectors in ``in-the-wild'' settings can experience performance inconsistencies due to dataset bias and distribution shift, which can manifest as unstable or inconsistent recognition of locally common vehicle types not well represented in the original training domain \parencite{Koh2021,TorralbaEfros2011}. In the Philippine context, where two-wheel vehicles are widely used and motorcycles comprise a large portion of registered vehicles, such inconsistencies can affect downstream tracking stability and violation inference quality \parencite{Inquirer2021,TorralbaEfros2011}. Specifically, the study seeks to:

\begin{enumerate}
  \item Implement a tracking-by-detection MOT pipeline that maintains stable vehicle identities across frames under occlusion, entry/exit events, and fluctuating detection confidence commonly observed in real traffic video \parencite{Wen2020,Zhang2022}.
  \item Design and integrate a fuzzy logic-based mechanism within MOT (e.g., for association or class-consistency handling) to explicitly manage uncertainty and reduce identity/class instability caused by detector-score variability and domain shift \parencite{Fakhri2023,Zadeh1965}.
  \item Formulate and validate interpretable geometric and region-based rules (e.g., lane boundary crossing, prohibited region entry, and other trajectory--boundary relations) to infer traffic violations from tracked trajectories in an auditable manner \parencite{Olugbade2022,Rathore2021}.
  \item Evaluate the system's violation detection performance and robustness across typical surveillance conditions (e.g., varying illumination, partial occlusions, and perspective distortion) that are known to affect detection and tracking consistency in traffic scenes \parencite{Wen2020,Zhang2022}.
  \item Produce evidence-oriented outputs (e.g., annotated frames, timestamps, track identifiers, and rule-trigger traces) that support review and verification of detected violations within camera-based enforcement workflows \parencite{MMDA2022,Olugbade2022}.
\end{enumerate}
\section{Theoretical Framework}
This study adopts a pipeline-oriented framework for automated traffic violation detection (ATVD) in which a violation is treated as a temporal event inferred from object trajectories, rather than as a purely frame-level classification outcome \parencite{Olugbade2022,Wen2020}. The framework is grounded in three coupled layers: perception, temporal continuity, and rule-based violation reasoning, which reflect how many practical systems operationalize traffic video analytics for monitoring and enforcement \parencite{Olugbade2022,Wen2020}.

In the perception layer, YOLO-based object detection produces frame-level observations (bounding boxes and classes) for vehicles at real-time-friendly speeds, providing the primary inputs required by downstream tracking \parencite{RedmonFarhadi2018}. However, modern computer vision models trained on large datasets can exhibit dataset-specific ``signatures'' and cross-dataset generalization gaps, meaning that performance can degrade when the deployment environment differs from the training environment \parencite{Koh2021,TorralbaEfros2011}. Such distribution shifts can be amplified in traffic monitoring due to differences in camera viewpoint, local vehicle taxonomy, and scene context \parencite{Koh2021,Wen2020}.

In the temporal continuity layer, MOT is used to associate detections across frames to yield stable identities and trajectories, enabling reasoning about lane-level behaviors and movements across regions of interest \parencite{Wen2020}. Tracking-by-detection methods emphasize that identity fragmentation often arises when low-confidence detections are discarded or when association is brittle under occlusion and score fluctuations \parencite{Zhang2022}. To address uncertainty arising from imperfect detections and domain shift, this study incorporates fuzzy logic as an uncertainty-handling mechanism within MOT, leveraging the fuzzy set principle of graded membership to represent ambiguous evidence and support more stable decision-making under imprecision \parencite{Fakhri2023,Zadeh1965}.

In the violation reasoning layer, geometric rules translate trajectories into interpretable violation events by evaluating track movements relative to lane boundaries, stop lines, or prohibited regions, which supports auditability compared to purely end-to-end ``black-box'' offense classification \parencite{Olugbade2022,Rathore2021}. This approach aligns with prior lane- and region-based violation detection work, where road geometry (lines, lanes, and zones) acts as the explicit constraint system against which tracked movement is evaluated \parencite{Olugbade2022,Rathore2021}. Taken together, the framework positions reliable detection as necessary but not sufficient: consistent tracking and explicit rule reasoning are treated as the core mechanisms that enable explainable, reviewable violation inference in real-world traffic surveillance \parencite{Olugbade2022,Zhang2022}.
\section{Significance of the Study}
This study is significant because road traffic injury remains a major public safety issue globally, and effective traffic law enforcement and compliance are widely recognized as important contributors to reducing crash risks and related harms \parencite{WHO2023Road}. In practice, scaling enforcement through video analytics can reduce reliance on continuous manual monitoring while enabling consistent capture of observable driving behaviors, particularly in dense urban settings where violations can be frequent and transient \parencite{Olugbade2022,Wen2020}.

For Philippine-focused deployment, the study contributes by explicitly addressing the practical limitation that popular pre-trained detectors may behave inconsistently under local distribution shifts, potentially affecting the stability of downstream tracking and the reliability of rule-based violation inference \parencite{Koh2021,TorralbaEfros2011}. By integrating fuzzy logic into MOT, the study explores a principled way to represent uncertainty and stabilize decisions when evidence is noisy or partially conflicting---conditions that are typical in traffic surveillance and are amplified when the training domain differs from the deployment domain \parencite{Fakhri2023,Zadeh1965}. For traffic management stakeholders, the outputs of this work are intended to be evidence-oriented and reviewable (e.g., trajectories and rule-trigger traces), which supports operational verification and potential integration with camera-based apprehension practices that rely on recorded evidence \parencite{MMDA2022,Olugbade2022}. For researchers, the study offers an applied reference design that combines YOLO-based detection, MOT, fuzzy uncertainty handling, and geometric-rule inference, contributing to the growing body of work emphasizing that robust ``in-the-wild'' deployment requires explicit handling of distribution shift and uncertainty beyond standard in-domain benchmarks \parencite{Koh2021,Wen2020}.
\section{Scope and Delimitation}
This study focuses on traffic violations that can be inferred from vehicle trajectories and road geometry using monocular traffic video, specifically through a pipeline that integrates YOLO-based detection, MOT, fuzzy logic-assisted uncertainty handling in tracking, and geometric rules for violation inference \parencite{RedmonFarhadi2018,Olugbade2022,Zhang2022}. The scope includes designing region- and lane-based rule logic (e.g., boundary crossing and prohibited region entry) that can be operationalized using user-defined lane lines, zones, and reference boundaries within the camera view \parencite{Olugbade2022,Rathore2021}. The system evaluation is constrained to scenarios where the camera perspective and scene layout are sufficiently stable to allow consistent geometric rule application, consistent with common assumptions in lane- and region-based traffic analytics \parencite{Rathore2021,Wen2020}.

The study does not aim to develop a nationwide-ready generalized detector for all Philippine roads, because distribution shift across locations, cameras, and vehicle appearances is known to degrade out-of-distribution performance for machine learning systems \parencite{Koh2021,TorralbaEfros2011}. Instead, the work emphasizes improving practical consistency in tracking and rule inference under local vehicle and scene variability by introducing fuzzy logic into MOT to manage uncertainty \parencite{Fakhri2023,Zadeh1965}. The study also does not cover violations that require direct observation of driver attributes (e.g., helmet use, seatbelt use) or fine-grained interior cues, as these typically require different data and modeling assumptions than trajectory-based geometric reasoning \parencite{Brophy2023,Wen2020}. Additionally, the study does not include end-to-end legal adjudication processes; rather, it focuses on generating evidence-oriented, reviewable outputs (e.g., annotated trajectories and rule-trigger traces) that can support verification within camera-based traffic monitoring or enforcement workflows \parencite{MMDA2022,Olugbade2022}.
\section{Definition of Terms}
For clarity and consistency, the following terms are defined as they are used in this study.

\begin{description}
  \item[\textbf{Artificial Intelligence (AI)}] refers to the field of developing systems that perform tasks associated with intelligent behavior, commonly framed around rational agents that perceive their environment and act to achieve goals \parencite{RussellNorvig2021}.
  \item[\textbf{Automated Traffic Violation Detection (ATVD)}] refers to using computational methods (typically computer vision pipelines) to automatically identify traffic rule violations from visual data such as video streams by detecting road users, analyzing their movement, and inferring violation events \parencite{Olugbade2022}.
  \item[\textbf{Bounding Box}] refers to a rectangular region that localizes an object in an image, typically represented by pixel coordinates and used as the basic output unit for modern object detectors and trackers \parencite{Zhao2019}.
  \item[\textbf{Camera Calibration}] refers to estimating camera parameters (intrinsic and/or extrinsic) required to relate image measurements to scene geometry, which is commonly needed for measurement tasks such as mapping image points to real-world coordinates \parencite{HartleyZisserman2004}.
  \item[\textbf{Class Label}] refers to the categorical output assigned to a detected object (e.g., ``car,'' ``motorcycle''), produced by an object detector as part of recognition and localization \parencite{Zhao2019}.
  \item[\textbf{Confidence Score}] refers to a detector's numeric estimate of how likely a predicted bounding box contains an object (and/or belongs to a particular class), which is often used for thresholding and association in tracking-by-detection pipelines \parencite{RedmonFarhadi2018,Zhang2022}.
  \item[\textbf{Computer Vision}] refers to the field of enabling computers to extract, interpret, and reason about information from images and video, including tasks such as detection, tracking, and geometric reasoning \parencite{Szeliski2022}.
  \item[\textbf{Data Association}] refers to the process in Multi-Object Tracking (MOT) of matching detections across frames to maintain consistent object identities over time \parencite{Zhang2022}.
  \item[\textbf{Dataset Bias}] refers to systematic differences and ``signatures'' across datasets that can lead to models learning dataset-specific patterns, reducing reliability when models are applied to new environments \parencite{TorralbaEfros2011}.
  \item[\textbf{Distribution Shift}] refers to a mismatch between the training data distribution and the deployment/test distribution, which can substantially degrade model performance outside the training conditions \parencite{Koh2021}.
  \item[\textbf{Fine-Tuning}] refers to adapting a pre-trained model by continuing training on task- or domain-specific data to better fit a target environment \parencite{Koh2021}.
  \item[\textbf{Fuzzy Logic}] refers to a reasoning framework that represents uncertainty using degrees of truth (rather than binary true/false), enabling decision-making under imprecision and noisy evidence \parencite{Zadeh1965}.
  \item[\textbf{Fuzzy Set}] refers to a set in which membership is expressed in degrees (typically between 0 and 1), forming the theoretical basis for fuzzy logic and membership-based reasoning \parencite{Zadeh1965}.
  \item[\textbf{Geometric Rules}] refers to deterministic constraints defined over road geometry (e.g., lane boundaries, forbidden zones, boundary crossings) that translate tracked trajectories into interpretable violation events \parencite{Olugbade2022,Rathore2021}.
  \item[\textbf{Homography (Perspective Transformation)}] refers to a projective mapping between two planes (or between image and a planar scene representation), often used to transform image coordinates into a top-down or normalized view for geometry-based measurement \parencite{HartleyZisserman2004}.
  \item[\textbf{Identity Switch (ID Switch)}] refers to a tracking failure where a tracked identity incorrectly changes from one physical object to another, reducing trajectory reliability and downstream event inference \parencite{Zhang2022}.
  \item[\textbf{Intersection over Union (IoU)}] refers to an overlap metric computed as the intersection area divided by the union area of two bounding boxes, commonly used for detection evaluation and for association logic in tracking-by-detection \parencite{RedmonFarhadi2018,Zhao2019}.
  \item[\textbf{Lane Boundary}] refers to a lane-marking line (or an operational lane delimiter in the image plane) used to define allowable vehicle movement regions for lane- and region-based violation reasoning \parencite{Rathore2021}.
  \item[\textbf{Lane Violation}] refers to a violation inferred when a vehicle's trajectory crosses or occupies a lane/region that is designated as prohibited according to lane boundaries and rule constraints defined for the scene \parencite{Olugbade2022,Rathore2021}.
  \item[\textbf{Membership Function}] refers to a function that assigns a degree of membership (e.g., 0 to 1) to an element with respect to a fuzzy set, enabling graded representation of uncertain evidence \parencite{Zadeh1965}.
  \item[\textbf{Multi-Object Tracking (MOT)}] refers to estimating object states (e.g., bounding boxes) and maintaining object identities across frames in video so that consistent trajectories can be formed over time \parencite{Zhang2022}.
  \item[\textbf{Occlusion}] refers to partial or full obstruction of an object by another object or scene element, which commonly degrades detection confidence and increases tracking difficulty in traffic scenes \parencite{Zhang2022}.
  \item[\textbf{Out-of-Distribution (OOD)}] refers to inputs that differ meaningfully from the training distribution, often causing degraded model reliability compared with in-distribution performance \parencite{Koh2021}.
  \item[\textbf{Pre-trained Model}] refers to a model trained previously on a large dataset and later reused as a starting point for a new task or environment, often to reduce training cost and improve baseline performance \parencite{Koh2021}.
  \item[\textbf{Region of Interest (ROI)}] refers to a defined image area (e.g., lane segments, zones, stop lines) where analysis is applied, such as triggering violations when tracked trajectories enter or cross the ROI boundary \parencite{Olugbade2022}.
  \item[\textbf{Speed Estimation (Vision-Based)}] refers to estimating vehicle speed using visual measurements (e.g., displacement over time) often requiring calibration or geometric mapping from image space to real-world units \parencite{HartleyZisserman2004}.
  \item[\textbf{Tracking-by-Detection}] refers to the common MOT paradigm where an object detector runs on each frame and the tracker associates detections across frames to form identities and trajectories \parencite{Zhang2022}.
  \item[\textbf{Trajectory}] refers to the time-ordered sequence of positions (often bounding-box centers or footprints) of a tracked object across frames, used for behavior analysis and violation inference \parencite{Olugbade2022,Zhang2022}.
  \item[\textbf{You Only Look Once (YOLO)}] refers to a family of single-stage object detectors that predict bounding boxes and class probabilities directly from images in a unified network, typically enabling real-time detection performance \parencite{RedmonFarhadi2018}.
\end{description}

\chapter{REVIEW OF RELATED LITERATURE}
\section{Survey of Automated Traffic Violation Detection (ATVD)}
Automated Traffic Violation Detection (ATVD) systems autonomously identify and document traffic infractions such as speeding, red-light running, and illegal parking, thereby improving road safety and easing the burden on human enforcers \parencite{Olugbade2022}. In the literature, ATVD solutions are broadly grouped into sensor-based and AI-based approaches. Sensor-based systems depend on physical hardware (e.g., inductive loops, radar, lidar) embedded in or beside the roadway to register vehicle presence and speed \parencite{Jain2021}. Although accurate, they require high installation and maintenance costs and are difficult to reconfigure for evolving traffic patterns \parencite{Olugbade2022}. AI-based systems, in contrast, leverage computer-vision and machine-learning techniques to detect violations directly from video streams, offering greater scalability and adaptability. Recent deep-learning (DL) models such as YOLOv5/v8 and Faster R-CNN achieve up to 97.7\% accuracy in vehicle counting and 89.2\% in vision-only speed estimation \parencite{Mohan2025}.

In the Philippines, nationwide deployment is exemplified by the No-Contact Apprehension Policy (NCAP), which relies on AI-enabled video analytics to capture evidence and issue citations. Independent audits, however, highlight public resistance over detection inaccuracies, privacy concerns, and camera-coverage gaps during heavy rain or glare \parencite{MMDA2022}.
\section{AI-Based Automated Traffic Violation Detection (ATVD)}
Growing demand for scalable enforcement has accelerated the integration of DL and computer vision into ATVD. Core pipelines combine object detection, multi-object tracking, and behaviour analysis. YOLOv5/v8 offers real-time helmet-use detection with 95\% precision on the Malaysian HMD-1 dataset \parencite{GuptaBhatia2022}, whereas Faster R-CNN achieves $>90\\%$ recall for red-light violations in Beijing's RLVD-2021 benchmark \parencite{Liang2021}. Transformer-based detectors such as DETR further improve localisation in congested intersections; \textcite{Meinhardt2021} reduced false positives by 18\% on the UA-DETRAC challenge.

License-plate recognition (LPR) is commonly performed with Convolutional Neural Network--Long Short-Term Memory (CNN--LSTM) hybrids, which couple spatial feature extraction with temporal character decoding. \textcite{Chiu2022} reported 96\% plate-level accuracy under variable illumination.

AI-based ATVD now spans diverse use-cases: helmet detection for motorcyclists \parencite{GuptaBhatia2022}, red-light enforcement \parencite{Liang2021}, radar-free speed estimation using optical flow \parencite{ZhangWang2024}, and illegal-parking detection in smart-city pilot zones \parencite{Tangamus2023}.

Despite these advances, significant hurdles remain, particularly across developing countries in Southeast Asia, Africa, and Latin America. Scarcity of local datasets that capture region-specific vehicle types (e.g., jeepneys, boda-boda, tuk-tuks) and signage limits model generalisation \parencite{Mon2022}. Tropical weather and lighting extremes (heavy rain, glare, low-luminance nights) can reduce detection recall by 20--40\% \parencite{Brophy2023}. Edge-deployment constraints---limited bandwidth, intermittent power, and modest hardware budgets---remain understudied \parencite{HaiderFatima2024}. Dense, mixed-traffic environments introduce severe occlusion, calling for multimodal sensor fusion (radar + vision or thermal + vision), yet few prototypes exist outside laboratory trials. Finally, regulatory and governance challenges---from compliance with data-protection laws (e.g., the Philippine Data Privacy Act of 2012) to the absence of harmonised accuracy benchmarks---continue to hamper large-scale, ethical deployment \parencite{Olugbade2022}.

Addressing these gaps through locally curated datasets, weather-robust training pipelines, lightweight edge architectures, multimodal fusion, and transparent governance frameworks will be pivotal for scaling AI-driven traffic enforcement across developing regions.
\section{Overview of Object Detection}
Object detection is a foundational task in computer vision that involves both locating (via bounding-box regression) and identifying (via classification) instances of predefined object categories in images or video streams \parencite{Zhao2019}. Its impact extends far beyond traffic enforcement. For instance, in healthcare, it enables early diagnosis by spotting tumors in radiological scans \parencite{Liu2020}; in ecology, it supports biodiversity studies by detecting species in aerial footage \parencite{Norouzzadeh2018}; and in retail, it facilitates real-time shelf monitoring to track inventory levels \parencite{Borji2022}.

Earlier detection frameworks relied on handcrafted feature extractors such as Histogram of Oriented Gradients (HOG) paired with classifiers like support vector machines. While effective in controlled environments, these methods struggled with scale variance, complex backgrounds, and real-time constraints, prompting a paradigm shift toward deep learning (DL). DL-based methods learn hierarchical features directly from data, offering superior adaptability to cluttered or variable conditions. This led to the development of two-stage models like R-CNN, Fast R-CNN, and Faster R-CNN that generate region proposals before classification \parencite{Ren2015}, achieving strong performance but often at high computational cost.

To enable real-time inference, single-stage detectors such as SSD and the YOLO family \parencite{RedmonFarhadi2018} emerged, removing the proposal stage and instead directly predicting bounding boxes and class probabilities in one pass. While this architecture accelerated inference, early versions struggled with detecting small or densely packed objects. Advances such as YOLOv8 introduced anchor-free mechanisms and architectural refinements to improve performance under such constraints.

Recent attention has shifted toward transformer-based architectures. DETR \parencite{Carion2020} pioneered end-to-end detection using self-attention to model global context, thereby improving localization in cluttered scenes. However, its high latency prompted research into hybrid designs that retain transformer benefits while minimizing overhead. Lightweight attention modules---such as MobileViT and ViT-lite---have demonstrated promise by embedding contextual reasoning within efficient backbones, making them suitable for edge deployments \parencite{MehtaRastegari2021}.

Despite these advances, challenges persist. Many transformer-based models remain resource-intensive, limiting their use in embedded systems. Moreover, their performance gains on large objects do not always translate to small-object detection, a frequent need in traffic scenarios involving helmets, plates, or signage. These limitations have motivated the integration of transformer-style attention into single-stage frameworks---offering a middle ground that balances accuracy, efficiency, and real-time suitability for dynamic urban environments.
\section{Lightweight Attention-Enhanced Single-Stage Detectors in Edge Applications}
Among the broad spectrum of object detection paradigms, recent literature has increasingly emphasized lightweight, transformer-augmented single-stage detectors as a promising compromise between accuracy and computational efficiency. These models aim to bring the benefits of contextual reasoning---previously the domain of high-end transformers---into compact architectures suited for edge deployment.

A notable example is YOLOv8-n, a streamlined variant within the YOLO family, which prioritizes inference speed and low memory footprint without severely compromising accuracy \parencite{Jocher2023}. When paired with attention modules like MobileViT \parencite{MehtaRastegari2021}, the resulting hybrid architecture can better capture fine-grained context, improving performance on small-object detection---an essential capability in domains such as medical imaging (e.g., cell detection), agriculture (e.g., pest identification), and autonomous traffic monitoring (e.g., helmet or license plate recognition).

These models have demonstrated real-world utility in applications that demand both precision and portability. For instance, lightweight detectors with embedded attention have been deployed on UAVs for crop monitoring \parencite{Gao2022} and on roadside edge devices for vehicle classification \parencite{Kim2023}. Enhancements such as structured pruning \parencite{Han2015} and quantization-aware training \parencite{Jacob2018} further reduce model size and latency, enabling deployment on devices like NVIDIA Jetson and Raspberry Pi, commonly used in smart-city pilots.

Compared to heavier architectures like Faster R-CNN or DETR, these hybrid single-stage detectors avoid the latency bottleneck of region proposals while compensating for the contextual limitations of convolutional backbones. Empirical evaluations on datasets such as UA-DETRAC show that MobileViT-enhanced YOLOv8-n achieves a 4--6\% improvement in mean average precision (mAP) with only a minor latency penalty \parencite{Wen2020}. In region-specific pilots---for example, helmet detection in Southeast Asian urban settings---such models have reported a 9\% recall gain over baseline YOLOv8-n, suggesting their effectiveness in dense, occlusion-prone environments.

Additionally, many implementations support modular extensions like license plate recognition (LPR) using CNN--LSTM decoders and federated learning protocols for privacy-compliant model updates across jurisdictions. These features position attention-enhanced lightweight detectors as a viable foundation for scalable, real-time ATVD systems, especially in regions where bandwidth, hardware, and regulatory compliance impose strict constraints.

\chapter{METHODOLOGY}
\section{Research Design}
\section{Study Setting and Camera Assumptions}
\section{Data Acquisition and Video Collection Plan}
\subsection{Data Sources}
\subsection{Inclusion Criteria}
\subsection{Data Partitioning}
\section{System Overview}
\section{Vehicle Detection and Classification}
\section{Multi-Object Tracking and Fuzzy Logic Stabilization}
\subsection{Baseline Tracker}
\subsection{Motivation for Fuzzy Logic in Association}
\subsection{Fuzzy-Enhanced Association and Class Stabilization}
\section{Manual Geometric Calibration}
\subsection{ROI Definition}
\subsection{Homography Calibration via Reference Rectangle}
\subsection{Ground-Contact Point Selection}
\section{Speed Estimation and Speeding Detection}
\subsection{Instantaneous Speed Computation}
\subsection{Temporal Smoothing}
\subsection{Speeding Event Rule}
\section{Geometric Rule-Based Violation Detection}
\subsection{Lane Misuse (Restricted Lane Violation)}
\subsection{No-Stopping / Loading-Zone Violation}
\subsection{Wrong-Way Driving / Counterflow}
\subsection{Illegal U-Turn}
\section{Evidence Generation and System Outputs}
\section{Performance Evaluation}
\subsection{Object Detection Metrics}
\subsection{Tracking Metrics}
\section{Experimental Design}
\subsection{Ablation on Fuzzy Logic Layer}
\subsection{Robustness Across Traffic Density and Lighting}
\section{Implementation Tools and Environment}
\section{Ethical and Practical Considerations}

\printbibliography

\end{document}
